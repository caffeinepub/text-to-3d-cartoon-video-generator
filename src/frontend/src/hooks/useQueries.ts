import { useQuery, useMutation, useQueryClient } from '@tanstack/react-query';
import { useActor } from './useActor';
import type { AnimationData, UserPreferences, EmotionalTone, AudioSettings } from '@/backend';
import { ExternalBlob } from '@/backend';

export function useGetAllAnimations() {
  const { actor, isFetching } = useActor();

  return useQuery<AnimationData[]>({
    queryKey: ['animations'],
    queryFn: async () => {
      if (!actor) return [];
      return actor.getAllAnimations();
    },
    enabled: !!actor && !isFetching,
  });
}

export function useGetAnimation(id: string) {
  const { actor, isFetching } = useActor();

  return useQuery<AnimationData>({
    queryKey: ['animation', id],
    queryFn: async () => {
      if (!actor) throw new Error('Actor not initialized');
      return actor.getAnimation(id);
    },
    enabled: !!actor && !isFetching && !!id,
  });
}

export function useGetUserPreferences() {
  const { actor, isFetching } = useActor();

  return useQuery<UserPreferences>({
    queryKey: ['userPreferences'],
    queryFn: async () => {
      if (!actor) throw new Error('Actor not initialized');
      return actor.getUserPreferences();
    },
    enabled: !!actor && !isFetching,
  });
}

interface GenerateAIAnimationParams {
  prompt: string;
  emotionalTone: EmotionalTone;
  audioSettings: AudioSettings;
}

export function useGenerateAIAnimation() {
  const { actor } = useActor();
  const queryClient = useQueryClient();

  return useMutation({
    mutationFn: async ({ prompt, emotionalTone, audioSettings }: GenerateAIAnimationParams) => {
      if (!actor) throw new Error('Actor not initialized');
      
      // Create placeholder blobs for the AI-generated animation
      // In a real implementation, these would be generated by an AI service
      const modelBlob = ExternalBlob.fromBytes(new Uint8Array([1, 2, 3]));
      const textureBlob = ExternalBlob.fromBytes(new Uint8Array([4, 5, 6]));
      const animationBlob = ExternalBlob.fromBytes(new Uint8Array([7, 8, 9]));
      const videoBlob = ExternalBlob.fromBytes(new Uint8Array([10, 11, 12]));
      
      // Create placeholder audio blobs
      const narrationAudioBlob = audioSettings.includeNarration 
        ? ExternalBlob.fromBytes(new Uint8Array([13, 14, 15]))
        : ExternalBlob.fromBytes(new Uint8Array([]));
      
      const backgroundAudioBlob = audioSettings.includeSoundEffects
        ? ExternalBlob.fromBytes(new Uint8Array([16, 17, 18]))
        : ExternalBlob.fromBytes(new Uint8Array([]));
      
      return actor.generateAIAnimation(
        prompt,
        emotionalTone,
        audioSettings,
        modelBlob,
        textureBlob,
        animationBlob,
        videoBlob,
        narrationAudioBlob,
        backgroundAudioBlob
      );
    },
    onSuccess: () => {
      // Invalidate animations query to refetch the list
      queryClient.invalidateQueries({ queryKey: ['animations'] });
    },
  });
}

export function useGetAIGeneratedAnimations() {
  const { actor, isFetching } = useActor();

  return useQuery<AnimationData[]>({
    queryKey: ['animations', 'ai-generated'],
    queryFn: async () => {
      if (!actor) return [];
      return actor.getAIGeneratedAnimations();
    },
    enabled: !!actor && !isFetching,
  });
}
